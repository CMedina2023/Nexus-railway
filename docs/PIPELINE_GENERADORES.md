# Pipeline de Generaci√≥n - Nexus Railway

El pipeline de generaci√≥n implementado en Nexus Railway es un sistema de **6 pasos** que orquesta la creaci√≥n de historias de usuario y casos de prueba mediante IA, con validaci√≥n sem√°ntica, cr√≠tica autom√°tica y ensamblaje protegido.

---

## Arquitectura del Pipeline

### Componentes Principales

1. **GenerationOrchestrator** (`app/services/generation_orchestrator.py`)
   - Orquesta el flujo completo de generaci√≥n
   - Coordina validaci√≥n, transformaci√≥n y persistencia
   - Emite eventos SSE para seguimiento en tiempo real

2. **Generadores Especializados** (`app/backend/generators/`)
   - `StoryGenerator`: Genera historias de usuario
   - `MatrixGenerator`: Genera casos de prueba
   - Implementan patr√≥n Strategy con clase base `Generator`

3. **Servicios de Soporte**
   - `DataTransformer`: Limpieza y normalizaci√≥n de datos
   - `Validator`: Validaci√≥n sem√°ntica y estructural
   - `FileGenerator`: Generaci√≥n de archivos (DOCX, CSV, JSON, ZIP)

---

## Pipeline de 6 Pasos

### **Paso 0: Inyecci√≥n de Contexto Global** üîÑ
```
Entrada: project_key (opcional)
Proceso: Carga contexto persistido del proyecto desde BD
Salida: Par√°metros enriquecidos con reglas de negocio y glosario
```

**Objetivo**: Enriquecer la generaci√≥n con contexto empresarial espec√≠fico del proyecto.

---

### **Paso 1: Generaci√≥n Inicial con LLM** ü§ñ
```
Entrada: Documento + Par√°metros (rol, contexto, √°rea)
Proceso: 
  - Extracci√≥n de Contexto Global (para historias)
  - Identificaci√≥n de actores y perfiles
  - Generaci√≥n de historias/casos con IA
  - Aplicaci√≥n de contexto de negocio
Salida: Contenido generado en bruto
```

**Caracter√≠sticas**:
- Ejecuci√≥n en **hilo separado** para evitar bloqueos
- Progreso simulado con mensajes descriptivos
- Heartbeat cada 2s para mantener conexi√≥n SSE viva
- Estrategia de "Dos Pasadas" para historias (contexto global ‚Üí generaci√≥n individual)

---

### **Paso 2: Evaluaci√≥n por LLM Critic** üîç
```
Entrada: Contenido generado
Proceso: An√°lisis cr√≠tico de calidad y coherencia
Salida: Recomendaciones de mejora (activado si hay fallos en Paso 3)
```

**Objetivo**: Detectar inconsistencias l√≥gicas antes de validaci√≥n formal.

---

### **Paso 3: Validaci√≥n Sem√°ntica Profunda** ‚úÖ
```
Entrada: Historias/Casos generados
Proceso:
  - Validaci√≥n de coherencia con documento original
  - Verificaci√≥n de criterios de aceptaci√≥n
  - Detecci√≥n de ambig√ºedades
Salida: Lista de issues encontrados
```

**Validadores**:
- `semantic_validate_story()`: Para historias de usuario
- `semantic_validate_case()`: Para casos de prueba

---

### **Paso 4: Verificaci√≥n de Calidad** üéØ
```
Entrada: Contenido validado sem√°nticamente
Proceso: Verificaci√≥n de est√°ndares de calidad
Salida: Confirmaci√≥n de calidad
```

**Nota**: La validaci√≥n sem√°ntica ya se ejecuta en el backend, este paso es principalmente visual.

---

### **Paso 5: Validaci√≥n Final de Integridad** üõ°Ô∏è
```
Entrada: Contenido procesado
Proceso:
  - Validaci√≥n estructural completa
  - Verificaci√≥n de campos obligatorios
  - Filtrado de elementos inv√°lidos
Salida: Contenido final validado
```

**M√©todos**:
- `validate_stories()`: Retorna historias v√°lidas + mensaje de error
- `validate_test_cases()`: Retorna casos v√°lidos + mensaje de error

---

### **Paso 6: Ensamblaje Protegido** üì¶
```
Entrada: Contenido validado
Proceso:
  1. Generaci√≥n de archivos (DOCX, CSV, JSON)
  2. Creaci√≥n de HTML para preview
  3. Persistencia en base de datos
  4. Empaquetado en ZIP (si aplica)
Salida: Archivos descargables + datos para UI
```

**Persistencia**:
- Historias ‚Üí Tabla `user_stories`
- Casos de Prueba ‚Üí Tabla `test_cases`
- Incluye: `user_id`, `project_key`, `area`, `content` (JSON), timestamps

---

## Flujo de Datos

```
Documento PDF/TXT
    ‚Üì
[Paso 0] Inyecci√≥n de Contexto
    ‚Üì
[Paso 1] LLM Generaci√≥n (Hilo separado)
    ‚Üì
[Paso 2] LLM Critic 
    ‚Üì
[Paso 3] Validaci√≥n Sem√°ntica
    ‚Üì
[Paso 4] Verificaci√≥n de Calidad
    ‚Üì
[Paso 5] Validaci√≥n de Integridad
    ‚Üì
[Paso 6] Ensamblaje + BD + Archivos
    ‚Üì
Respuesta SSE con URLs de descarga
```

---

## Comunicaci√≥n SSE (Server-Sent Events)

### Formato de Mensajes
```json
{
  "message": "Extrayendo Contexto Global...",
  "progress": 15,
  "status": "Contexto Global",
  "terminal": false,
  "data": null
}
```

### Estados del Pipeline
- **Inicio**: Progreso 0-10%
- **Generaci√≥n IA**: Progreso 10-70%
- **Validaci√≥n**: Progreso 70-90%
- **Ensamblaje**: Progreso 90-100%
- **completed**: Pipeline exitoso
- **error**: Fallo en alg√∫n paso

---

## Estrategia de Dos Pasadas (Historias)

### Primera Pasada: Extracci√≥n de Contexto Global
- Identifica reglas de negocio transversales
- Construye glosario de t√©rminos
- Detecta dependencias entre requisitos

### Segunda Pasada: Generaci√≥n Individual
- Aplica contexto global a cada historia
- Genera criterios de aceptaci√≥n contextualizados
- Asegura consistencia narrativa

**Beneficio**: Historias m√°s coherentes y alineadas con el negocio.

---

## Manejo de Errores

### Niveles de Error
1. **Error en Generaci√≥n IA**: Retorna mensaje de error + progreso 0
2. **Error en Validaci√≥n**: Limpia archivos temporales + mensaje descriptivo
3. **Error en BD**: Loguea warning pero contin√∫a el flujo
4. **Error Inesperado**: Captura en `try-except` + evento SSE de error

### Recuperaci√≥n
- Archivos temporales se limpian autom√°ticamente en caso de fallo
- Conexi√≥n SSE se mantiene viva con heartbeats
- Logs detallados en `logger` para debugging

---

## Tipos de Generaci√≥n

### 1. Solo Historias (`task_type='story'`)
- Genera archivo `.docx` con historias
- Incluye HTML preview + CSV para Jira
- Persiste en tabla `user_stories`

### 2. Solo Casos de Prueba (`task_type='matrix'`)
- Genera `.zip` con JSON + CSV
- Incluye HTML preview
- Persiste en tabla `test_cases`

### 3. Generaci√≥n Combinada (`task_type='both'`)
- Ejecuta ambos pipelines en secuencia
- Genera `.zip` combinado con todos los archivos
- Persiste en ambas tablas

---

## Optimizaciones Implementadas

1. **Ejecuci√≥n As√≠ncrona**: IA corre en hilo separado
2. **Progreso Fluido**: Simulaci√≥n sincronizada con pasos reales
3. **Heartbeat**: Mantiene conexi√≥n viva en proxies (Nginx)
4. **Validaci√≥n Incremental**: Detecta errores temprano
5. **Cach√© de Contexto**: Reutiliza contexto global del proyecto
6. **Batch Processing**: Procesa historias en lotes para eficiencia

---

## M√©tricas de Rendimiento

- **Tiempo Promedio**: 30-60 segundos (depende del tama√±o del documento)
- **Heartbeat Interval**: 2 segundos
- **Delay entre Pasos Simulados**: 3-5 segundos
- **Timeout de Proxy**: Evitado con heartbeats

---

## Pr√≥ximas Mejoras (Roadmap)

- [ ] Implementar repositorio de contexto de proyecto (K1.5)
- [ ] Activar LLM Critic de forma autom√°tica
- [ ] Paralelizar generaci√≥n de historias y casos
- [ ] Agregar m√©tricas de calidad en respuesta
- [ ] Implementar retry autom√°tico en fallos transitorios

---

## Referencias T√©cnicas

- **Orquestador**: `app/services/generation_orchestrator.py`
- **Generadores**: `app/backend/generators/`
- **Validadores**: `app/services/validator.py`
- **Transformadores**: `app/services/data_transformer.py`
- **Repositorios**: `app/database/repositories/`

---
